{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "\n",
    "## Installation\n",
    "- Cuda\n",
    "- CuDNN\n",
    "- scipy\n",
    "- numpy\n",
    "- Tensorflow\n",
    "- Keras\n",
    "- Pandas\n",
    "- H5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "\n",
    "1. Update apt-get\n",
    "    ~~~\n",
    "    sudo apt-get update\n",
    "    ~~~\n",
    "2. Install dependencies\n",
    "    ~~~\n",
    "    sudo apt-get install libglu1-mesa libxi-dev libxmu-dev -y\n",
    "    sudo apt-get install build-essential -y\n",
    "    sudo apt-get install python3-pip python3-dev -y\n",
    "    sudo apt-get install python3-numpy python3-scipy -y\n",
    "    sudo apt-get install python3-virtualenv virtualenv -y\n",
    "    sudo apt-get install python-yaml -y\n",
    "    sudo apt-get install libhdf5-serial-dev -y\n",
    "    ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install CUDA\n",
    "\n",
    "Cuda is architecture platform supporting parallel computing created by Nvidia. It is essentially a software layer between the CPU and the GPU. Cuda is well-suited for both graphical applications like 2D or 3D modelling, graphic intensive video games as well as computational applications in biology or in crypography. Interestingly, machine learning applications can be both graphically as well as computationally intensive. Hence, every library or framework that we are going to talk about comes with cuda support. The cuda toolkit has inbuilt libraries performing important computations involving linear algebra, fast fourier transforms etc. Cuda makes single threaded workflow on CPU and accelarated parallel processing on GPU possible. The cuda execution model has three parts- grids, blocks and threads.The grid runs on a device(GPU), blocks run on multi processors and threads run on scalar processor(cores). With cuda, hardware resource allotment for thousands of threads running in hundreds or thousands of GPU cores over millions or even billions of transistors is made extremely efficient. Cuda essentially splits up code into threads by itself and assigns them to GPU cores thus highly speeding up computing.\n",
    "\n",
    "### Deb file method\n",
    "\n",
    "1. Check if you have nvidia graphic card by running the following command in the terminal\n",
    "    \n",
    "    ~~~~\n",
    "    lspci -nnk | grep -i nvidia\n",
    "    ~~~~\n",
    "   If there is no output then you can skip to installing scipy.\n",
    "2. Goto https://developer.nvidia.com/cuda-downloads and download the deb (local) file for your system. To check distribution run\n",
    "    ~~~\n",
    "    uname -m && cat /etc/*release\n",
    "    ~~~\n",
    "3. Install repository meta-data\n",
    "    ~~~\n",
    "    sudo dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb\n",
    "    ~~~\n",
    "    Update apt repository cache\n",
    "    ~~~\n",
    "    sudo apt-get update\n",
    "    ~~~\n",
    "    Install CUDA\n",
    "    ~~~\n",
    "    sudo apt-get install cuda\n",
    "    ~~~\n",
    "4. Open .bashrc\n",
    "    ~~~\n",
    "    nano ~/.bashrc\n",
    "    ~~~\n",
    "    Add the following lines to the end of the file\n",
    "    ~~~\n",
    "    export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}\n",
    "    ~~~\n",
    "    Exit out of nano by pressing Ctrl+x then y and then enter\n",
    "    Now run the following command\n",
    "    ~~~\n",
    "    source ~/.bashrc\n",
    "    ~~~\n",
    "5. Verify driver installation\n",
    "    ~~~\n",
    "    cat /proc/driver/nvidia/version\n",
    "    ~~~\n",
    "   Verify cuda installation\n",
    "    ~~~\n",
    "    nvcc -V\n",
    "    ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run file method\n",
    "\n",
    "Use this method if the deb file method doesn't work.\n",
    "\n",
    "1. Check if you have nvidia graphic card by running the following command in the terminal\n",
    "    ~~~~\n",
    "    lspci -nnk | grep -i nvidia\n",
    "    ~~~~\n",
    "   If there is no output then you can skip to installing scipy.\n",
    "2. Goto https://developer.nvidia.com/cuda-downloads and download the run file for your system.\n",
    "3. Disable Nouveau drivers\n",
    "    ~~~\n",
    "    sudo nano /etc/modprobe.d/blacklist-nouveau.conf\n",
    "    ~~~\n",
    "   Write the following inside the file and press Ctrl+x and then Enter\n",
    "    ~~~\n",
    "    blacklist nouveau \n",
    "    options nouveau modeset=0\n",
    "    ~~~\n",
    "   Run the following in terminal to update initial RAM filesystem \n",
    "    ~~~\n",
    "    sudo update-initramfs -u\n",
    "    ~~~\n",
    "4. Run the following command to make run file executable\n",
    "    ~~~\n",
    "    sudo chmod +x cuda_8.0_linux.run\n",
    "    ~~~\n",
    "5. Reboot Ubuntu and press Alt+F1 when prompted for login\n",
    "6. Purge any nvidia packages \n",
    "    ~~~\n",
    "    sudo apt-get remove --purge nvidia*\n",
    "    sudo apt-get autoremove\n",
    "    ~~~\n",
    "7. Run the following command to install CUDA\n",
    "    ~~~\n",
    "    sudo ./cuda_8.0_linux.run --override\n",
    "    ~~~\n",
    "8. Open .bashrc\n",
    "    ~~~\n",
    "    nano ~/.bashrc\n",
    "    ~~~\n",
    "    Add the following lines to the end of the file\n",
    "    ~~~\n",
    "    #CUDA Toolkit\n",
    "    export CUDA_HOME=/usr/local/cuda-8.0\n",
    "    export LD_LIBRARY_PATH=${CUDA_HOME}/lib64:$LD_LIBRARY_PATH\n",
    "    export PATH=${CUDA_HOME}/bin:${PATH}\n",
    "    ~~~\n",
    "    Exit out of nano by pressing Ctrl+x then y and then enter\n",
    "    Now run the following command and reboot\n",
    "    ~~~\n",
    "    source ~/.bashrc\n",
    "    sudo reboot\n",
    "    ~~~\n",
    "9. Verify driver installation\n",
    "    ~~~\n",
    "    cat /proc/driver/nvidia/version\n",
    "    ~~~\n",
    "   Verify cuda installation\n",
    "    ~~~\n",
    "    nvcc -V\n",
    "    ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install cuDNN\n",
    "\n",
    "The cuDNN library provides highly tuned implemntation of standard deep learning routines such as convolution, poolinng, normalization, activation, optimization. CuDNN accelaration GPU performance for deep learning frameworks like Tensorflow , Theano, Caffe etc.\n",
    "\n",
    "\n",
    "1. Register for a nvidia developer account and head over to https://developer.nvidia.com/cudnn and download cuDNN v5.1 for CUDA 8.0\n",
    "2. Unpack the file\n",
    "    ~~~\n",
    "    tar -xzvf cudnn-8.0-linux-x64-v5.1.tgz\n",
    "    ~~~\n",
    "    Copy cuDNN files to cuda folder \n",
    "    ~~~\n",
    "    sudo cp cuda/lib64/* /usr/local/cuda/lib64/\n",
    "    sudo cp cuda/include/cudnn.h /usr/local/cuda/include/\n",
    "    ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Set up Virtualenv\n",
    "\n",
    "1. Create virtual environment\n",
    "    ~~~\n",
    "    virtualenv --system-site-packages ~/kerai\n",
    "    ~~~\n",
    "2. Activate virtual environment, this is what you need to run every time you want to work with tensorflow and keras\n",
    "    ~~~\n",
    "    source ~/kerai/bin/activate\n",
    "    ~~~\n",
    "    Your terminal prompt should change to \n",
    "    ~~~\n",
    "    (kerai)$\n",
    "    ~~~\n",
    "    To deactivate the virtual environment execute\n",
    "    ~~~\n",
    "    deactivate\n",
    "    ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install tensorflow\n",
    "\n",
    "Tensorflow is an open source library for end-to end machine learning apllications. It was developed by Google's Brain team and is written in python, C++, cuda. It is based on stateful dataflow graphs distributed over tensorflow sessions using multidimensional arrays called tensors. Tensorflow has inbuilt tensorboard for visualizing the graphs.\n",
    "\n",
    "- If you do not have a Nvidia graphics card the run the following command\n",
    "    ~~~\n",
    "    (kerai)$ pip3 install --upgrade tensorflow\n",
    "    ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you have Nvidia graphic card and installed CUDA and cuDNN then run\n",
    "    ~~~\n",
    "    (kerai)$ pip3 install --upgrade tensorflow-gpu \n",
    "    ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Keras\n",
    "\n",
    "Keras is a essentially a model based library written in native python for building and deploying neural networks. It was too developed by a Google engineer. It can run over Theano or Tensorflow backend. The key feature of keras is its **readability** and **modularity** without diving into tensorflow or theano.\n",
    "- Install keras in the virtualenv\n",
    "    ~~~\n",
    "    (kerai)$ pip3 install keras\n",
    "    ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install optional libraries\n",
    "\n",
    "- Pandas\n",
    "    ~~~\n",
    "    (kerai)$ pip3 install pandas\n",
    "    ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- H5py to save models\n",
    "    ~~~\n",
    "    (kerai)$ pip3 install h5py\n",
    "    ~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if CUDA is working with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
